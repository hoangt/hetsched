\section{Porting guide}
\label{Porting}

The best way to port an application to the new framework depends on the existing structure of the application. In this guide we will try to cover some possibilities.

In every case the application has to define suitable checkpoints, so that the cooperative multitasking scheme can be applied. In the case of the exemplary applications this was easy, as both consisted mostly of one main loop, where the state of this loop could be saved in a few variables. This is not necessarily true for other applications, so checkpoints may be arbitrarily complex, and perhaps they do not reflect a program state at the beginning of a (main) loop, but any other point in the program. Anything is allowed in the definition of the checkpoints, as long as
\begin{itemize}
	\item a checkpoint is portable between the different implementations of the algorithm, so that the checkpoint is mappable between the implementations
	\item a checkpoint is as small as possible, as larger checkpoints yield a larger scheduling overhead and therefore a poorer performance
	\item a checkpoint is unambiguous, i.e. it completely identifies a unique program state (unless the application does not require this)
	\item the checkpoints are neither to close to each other nor to far apart, as the former introduces too much scheduling overhead, and the latter hinders the scheduler by occupying the resources too long
\end{itemize}

After defining such checkpoints, the application has to be reworked in a way that honors the checkpointing. To fit into the application model of the framework, it mainly has to consist of one function, which gets a checkpoint as parameter, and then has to execute the correct code that runs to the next checkpoint. At best, there should be one such function per supported accelerator after the transformation. These will be the \codesnippet{main} functions of the function triplets, returned by the \functionname{getImplementationFor} function. From this state it will be quite easy to port the application to the framework, as described in the next subsections.

\subsection{Single threaded application}
\label{Porting:STA}
To port a single threaded application to the framework, the simplest approach is to implement a new subclass of \codesnippet{Worker}, which represents the application. Testapp can be modified (in \functionname{Testapp::performWork()}) to spawn only one single worker (your application) and wait for its completion afterwards.

As the application can provide new meta information with every allocation system call, it is possible to provide new affinities to the computing units with every call. Using this, the application could have an initialization phase, which can only run on a CPU, and several accelerated portions, which only run on a GPU (note that you can disable the use of certain types of accelerators, using the affinities). It would inform the scheduler which type of computing unit it needs next, by just setting its meta information accordingly. It is therefore possible to define parts of the application which can run only on a single type of unit, and other parts which may be able to run on several types of units. To enable this behaviour however, minor changes to \functionname{Worker::startWorking()} would be needed. This main loop assumes, that after each application invocation (call to the \codesnippet{main} function pointer), the same computing unit can be re-requested for this application. Thus a new flag (e.g. \codesnippet{change\_cu}) would have to be introduced here.

Technically, the application does not need to re-request the computing unit at checkpoints in the CPU-only parts, as the original CFS-Scheduler of Linux will take care of the hardware task in this case, and any number of hardware tasks may be simultaneously on the CPUs. If furthermore the accelerated portions of the application run only for a few seconds (under $5$ or so), they can compute without interruption and just return the data in the usual way. The benefit of this technique would be the orchestrated use of the accelerators by all running applications, if they all adhere to the concept.

As mentioned in section \ref{Implementation:Userside:Framework}, the deriving class will at least have to implement the following:
\begin{enumerate}
	\item An implementation for the pure virtual function \functionname{workerMetaInfo}, which calculates the contents of the \codesnippet{meta\_info} structure from the problem parameters and available algorithm implementations. As mentioned above, the meta information may change over the course of the running time.
	\item A triplet of functions per supported device type that perform the following actions:
	\begin{itemize}
		\item Initialization of the \cu{}
		\item Execution of the code on the unit up to the next checkpoint - this is the \codesnippet{main} function mentioned at the beginning of this section
		\item Freeing of the resources allocated by the two above functions
	\end{itemize}
	\item An implementation for the pure virtual function \functionname{getImplementationFor}, which returns the triplet of functions that implement the algorithm for the given unit type. As indicated above, this function could be implemented in an application-state aware manner, where it returns different triplets for each unit, depending on the application state.
\end{enumerate}

\subsection{Multithreaded application, no thread interaction}
\label{Porting:MTAnti}
Additionally to the steps mentioned in section \ref{Porting:STA} for each thread, this model would just require the correct change to \functionname{Testapp::performWork()}. Each thread of the original application would correspond to a subclass of \codesnippet{Worker}, and therefore all of these workers have to be spawned at the start of Testapp.

\subsection{Multithreaded application, with thread interaction}
This model could be best implemented by following the steps from section \ref{Porting:MTAnti} and modifying the worker spawning mechanism to transmit the identifications (ids, or pthread pointers) of all communication partners to the workers which need them. Using these identification mechanism, the workers can interact with one another like any two pthreds, including sending signals, waiting on conditions, and so on. The programmer should bear in mind though, that if a task waits or sleeps, while holding a computing unit (called alloc, but not free), that this may create a deadlock for all threads. Therefore, the (sleeping) interaction should always be done after calling the syscall free. This would require a change to \functionname{Worker::startWorking()}, as in the current implementation of class \codesnippet{Worker} there is no callback to the derived worker intended at this point.

